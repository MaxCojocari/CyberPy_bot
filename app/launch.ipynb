{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "launch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMTek+P5S3hHKt+d5pb8P8u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaxCojocari/CyberPy_bot/blob/main/app/launch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYqoXyHEpwpe",
        "outputId": "df16b265-dff4-42b8-a225-1a8d71eee98b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfOJ-RT9fK4N",
        "outputId": "cbfa8b48-e997-4984-ecf1-8cc00e3d03b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (1.1.4)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask) (1.0.1)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask) (2.0.1)\n",
            "Collecting flask_ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask_ngrok) (2.23.0)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask_ngrok) (1.1.4)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (1.1.0)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (7.1.2)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (2.11.3)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask_ngrok) (2.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (3.0.4)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n",
            "Collecting pyngrok==4.1.1\n",
            "  Downloading pyngrok-4.1.1.tar.gz (18 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyngrok==4.1.1) (0.16.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok==4.1.1) (3.13)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-4.1.1-py3-none-any.whl size=15983 sha256=d472315900844e8b5f0cc4c57eb70f42e4a7e34193baeb07ceb64de5a675969b\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/d9/12/045a042fee3127dc40ba6f5df2798aa2df38c414bf533ca765\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-4.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install flask\n",
        "!pip install flask_ngrok\n",
        "!pip install pyngrok==4.1.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.vocab import GloVe\n",
        "glove = GloVe(name='6B', dim=50)"
      ],
      "metadata": {
        "id": "fP2y6lAwqGNt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f7d00fb-3293-48e5-8def-437f15339026"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:42, 5.30MB/s]                           \n",
            "100%|█████████▉| 399999/400000 [00:09<00:00, 43747.72it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwTr3uG4qV_k",
        "outputId": "95807b85-23a4-44c9-d76f-665112ae50da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask, jsonify, request\n",
        "import torch\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torch import nn\n",
        "from torchtext.vocab import GloVe\n",
        "\n",
        "import string\n",
        "\n",
        "\n",
        "#nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "list_stopwords = set(stopwords.words('english'))\n",
        "\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "glove = GloVe(name='6B', dim=50)\n",
        "\n",
        "def get_tokens(text):\n",
        "    tokens = [word for word in tokenizer(text) if word not in list_stopwords]\n",
        "    tokens = [word.translate(str.maketrans('', '', string.punctuation)) for word in tokens]\n",
        "    tokens = [word for word in tokens if len(word) > 1]\n",
        "    return tokens\n",
        "\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "    #define all the layers used in model\n",
        "    def __init__(self, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional=True, dropout=0.2):\n",
        "        \n",
        "        #Constructor\n",
        "        super().__init__()          \n",
        "        \n",
        "        #lstm layer\n",
        "        self.lstm = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=n_layers, \n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout=dropout,\n",
        "                           batch_first=True)\n",
        "        \n",
        "        #dense layer\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "        \n",
        "    def forward(self, embeds):\n",
        "        packed_output, (hidden, cell) = self.lstm(embeds)\n",
        "        \n",
        "        #concat the final forward and backward hidden state\n",
        "        hidden = torch.cat((hidden[-2, : , : ], hidden[-1, : , : ]), dim = 1)\n",
        "        #hidden = [batch size, hid dim * num directions]\n",
        "        dense_outputs = self.fc(hidden)\n",
        "\n",
        "        return dense_outputs\n",
        "\n",
        "\n",
        "device = torch.device('cpu')\n",
        "\n",
        "label2intent_1 = {0: 'not_cyberbullying', 1: 'gender', 2: 'religion', 3: 'age', 4: 'ethnicity'}\n",
        "label2intent_2 = {0: 'ham', 1: 'spam'}\n",
        "model1 = LSTM(50, 32, len(label2intent_1), 2).to(device)\n",
        "model2 = LSTM(50, 32, len(label2intent_2), 2).to(device)\n",
        "model1.load_state_dict(torch.load(\n",
        "    '/content/drive/MyDrive/NLPC2022/cyberbullying_lstm.pt', map_location='cpu'))\n",
        "model2.load_state_dict(torch.load(\n",
        "    '/content/drive/MyDrive/NLPC2022/spam_lstm.pt', map_location='cpu'))\n",
        "model1.eval()\n",
        "model2.eval()\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/', methods=['GET'])\n",
        "def index():\n",
        "    # request data from client\n",
        "    data = request.json\n",
        "    \n",
        "    # generate embeds for set of tokens\n",
        "    embeds = glove.get_vecs_by_tokens(get_tokens(data[\"text\"]))\n",
        "    embeds = embeds.view(1, embeds.shape[0], 50).to(device)\n",
        "    \n",
        "    # give predictions\n",
        "    output1, output2 = model1(embeds), model2(embeds)\n",
        "\n",
        "    # find predicted label\n",
        "    label_cyb = int(torch.max(output1, dim=1)[1][0])\n",
        "    label_spam = int(torch.max(output2, dim=1)[1][0])\n",
        "\n",
        "    # softmax perquisite\n",
        "    m = nn.Softmax(dim=1)\n",
        "    prob = m(output1)\n",
        "    \n",
        "    prediction1, prediction2 = 0, 0\n",
        "    \n",
        "    if label_cyb in [1, 2, 3, 4]:\n",
        "        prediction1 = 1\n",
        "    \n",
        "    prediction2 = int(label_spam)\n",
        "    \n",
        "    return jsonify({\n",
        "        \"cyberbullying\" : prediction1,\n",
        "        \"spam\" :  prediction2,\n",
        "        \"cyberbull_type\" : {\n",
        "            'not_cyberbullying': round(prob[0][0].item(), 4),\n",
        "            'gender': round(prob[0][1].item(), 4),\n",
        "            'religion': round(prob[0][2].item(), 4),\n",
        "            'age': round(prob[0][3].item(), 4),\n",
        "            'ethnicity': round(prob[0][4].item(), 4)\n",
        "        }\n",
        "    })\n",
        "\n",
        "run_with_ngrok(app)\n",
        "app.run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEu6-vOPpU5O",
        "outputId": "1352f4c9-e1a6-4c3c-a5b1-9b8a2cac4a14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Running on http://9865-34-80-27-204.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127.0.0.1 - - [04/May/2022 10:43:04] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0ZXX_14AwSZ_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}